#!/usr/bin/env python3
"""
Integrate Linux LLDB Archives with Python 3.10 Support

This script automates the integration of Linux LLDB archives built by GitHub Actions
into the clang-tool-chain distribution system.

Usage:
    # Download and integrate archives from latest workflow run
    python tools/integrate_lldb_linux_archives.py

    # Download from specific run ID
    python tools/integrate_lldb_linux_archives.py --run-id 12345678

    # Dry-run mode (no changes made)
    python tools/integrate_lldb_linux_archives.py --dry-run

    # Skip archive download (use existing files)
    python tools/integrate_lldb_linux_archives.py --skip-download

    # Integrate only one architecture
    python tools/integrate_lldb_linux_archives.py --arch x86_64
    python tools/integrate_lldb_linux_archives.py --arch arm64

Features:
    - Downloads artifacts from GitHub Actions workflow
    - Verifies SHA256 checksums
    - Tests archive extraction
    - Moves archives to correct distribution locations
    - Updates manifest files with metadata
    - Validates manifest structure
    - Comprehensive error handling
    - Dry-run mode for safe testing

Requirements:
    - GitHub CLI (gh) installed and authenticated
    - Python 3.10+
    - zstandard library (pip install zstandard)

Author: Generated by Claude Code
Date: 2026-01-06
"""

import argparse
import hashlib
import json
import os
import shutil
import subprocess
import sys
import tarfile
import tempfile
from pathlib import Path

try:
    import zstandard as zstd
except ImportError:
    print("Error: zstandard library not found. Install with: pip install zstandard")
    sys.exit(1)


class Colors:
    """ANSI color codes for terminal output"""

    HEADER = "\033[95m"
    OKBLUE = "\033[94m"
    OKCYAN = "\033[96m"
    OKGREEN = "\033[92m"
    WARNING = "\033[93m"
    FAIL = "\033[91m"
    ENDC = "\033[0m"
    BOLD = "\033[1m"
    UNDERLINE = "\033[4m"


def print_section(title: str) -> None:
    """Print a formatted section header"""
    print(f"\n{Colors.HEADER}{Colors.BOLD}{'=' * 80}{Colors.ENDC}")
    print(f"{Colors.HEADER}{Colors.BOLD}{title}{Colors.ENDC}")
    print(f"{Colors.HEADER}{Colors.BOLD}{'=' * 80}{Colors.ENDC}\n")


def print_success(message: str) -> None:
    """Print success message"""
    print(f"{Colors.OKGREEN}✓ {message}{Colors.ENDC}")


def print_error(message: str) -> None:
    """Print error message"""
    print(f"{Colors.FAIL}✗ {message}{Colors.ENDC}")


def print_warning(message: str) -> None:
    """Print warning message"""
    print(f"{Colors.WARNING}⚠ {message}{Colors.ENDC}")


def print_info(message: str) -> None:
    """Print info message"""
    print(f"{Colors.OKCYAN}ℹ {message}{Colors.ENDC}")


def run_command(
    cmd: list[str], check: bool = True, capture: bool = True
) -> tuple[int, str, str]:
    """
    Run a shell command and return (returncode, stdout, stderr)

    Args:
        cmd: Command and arguments as list
        check: Raise exception on non-zero exit code
        capture: Capture stdout and stderr

    Returns:
        Tuple of (returncode, stdout, stderr)
    """
    try:
        if capture:
            result = subprocess.run(cmd, check=check, capture_output=True, text=True)
            return result.returncode, result.stdout, result.stderr
        else:
            result = subprocess.run(cmd, check=check)
            return result.returncode, "", ""
    except subprocess.CalledProcessError as e:
        if capture:
            return e.returncode, e.stdout or "", e.stderr or ""
        else:
            return e.returncode, "", ""


def check_gh_cli() -> bool:
    """Check if GitHub CLI is installed and authenticated"""
    print_info("Checking GitHub CLI availability...")

    returncode, stdout, stderr = run_command(["gh", "--version"], check=False)
    if returncode != 0:
        print_error("GitHub CLI (gh) is not installed")
        print_info("Install from: https://cli.github.com/")
        return False

    print_success(f"GitHub CLI installed: {stdout.strip().split()[2]}")

    # Check authentication
    returncode, stdout, stderr = run_command(["gh", "auth", "status"], check=False)
    if returncode != 0:
        print_error("GitHub CLI is not authenticated")
        print_info("Run: gh auth login")
        return False

    print_success("GitHub CLI authenticated")
    return True


def get_latest_workflow_run() -> str | None:
    """Get the latest workflow run ID for build-lldb-archives-linux.yml"""
    print_info("Finding latest workflow run...")

    cmd = [
        "gh",
        "run",
        "list",
        "--workflow=build-lldb-archives-linux.yml",
        "--limit",
        "1",
        "--json",
        "databaseId,status,conclusion,displayTitle,createdAt",
    ]

    returncode, stdout, stderr = run_command(cmd, check=False)
    if returncode != 0:
        print_error(f"Failed to query workflow runs: {stderr}")
        return None

    runs = json.loads(stdout)
    if not runs:
        print_error("No workflow runs found for build-lldb-archives-linux.yml")
        return None

    run = runs[0]
    run_id = str(run["databaseId"])
    status = run["status"]
    conclusion = run.get("conclusion", "N/A")
    title = run["displayTitle"]
    created_at = run["createdAt"]

    print_success(f"Found run ID: {run_id}")
    print_info(f"  Title: {title}")
    print_info(f"  Status: {status}")
    print_info(f"  Conclusion: {conclusion}")
    print_info(f"  Created: {created_at}")

    if status != "completed":
        print_warning(f"Workflow run {run_id} has not completed yet (status: {status})")
        return None

    if conclusion != "success":
        print_error(f"Workflow run {run_id} did not succeed (conclusion: {conclusion})")
        return None

    return run_id


def download_artifacts(run_id: str, output_dir: Path, architectures: list[str]) -> bool:
    """Download artifacts from GitHub Actions workflow run"""
    print_info(f"Downloading artifacts from run {run_id}...")

    output_dir.mkdir(parents=True, exist_ok=True)

    for arch in architectures:
        artifact_name = f"lldb-linux-{arch}"
        print_info(f"Downloading {artifact_name}...")

        cmd = [
            "gh",
            "run",
            "download",
            run_id,
            "--name",
            artifact_name,
            "--dir",
            str(output_dir / artifact_name),
        ]

        returncode, stdout, stderr = run_command(cmd, check=False, capture=False)
        if returncode != 0:
            print_error(f"Failed to download {artifact_name}")
            return False

        print_success(f"Downloaded {artifact_name}")

    return True


def verify_checksum(archive_path: Path, checksum_path: Path) -> bool:
    """Verify SHA256 checksum of archive"""
    print_info(f"Verifying checksum for {archive_path.name}...")

    # Read expected checksum
    with open(checksum_path) as f:
        expected_line = f.read().strip()
        # Format: "<checksum>  <filename>" or "<checksum> *<filename>"
        expected_checksum = expected_line.split()[0]

    # Calculate actual checksum
    sha256_hash = hashlib.sha256()
    with open(archive_path, "rb") as f:
        for byte_block in iter(lambda: f.read(8192), b""):
            sha256_hash.update(byte_block)

    actual_checksum = sha256_hash.hexdigest()

    if actual_checksum == expected_checksum:
        print_success(f"Checksum verified: {actual_checksum[:16]}...")
        return True
    else:
        print_error("Checksum mismatch!")
        print_error(f"  Expected: {expected_checksum}")
        print_error(f"  Actual:   {actual_checksum}")
        return False


def test_archive_extraction(archive_path: Path) -> bool:
    """Test that archive can be extracted successfully"""
    print_info(f"Testing extraction of {archive_path.name}...")

    with tempfile.TemporaryDirectory() as tmpdir:
        try:
            # Decompress with zstandard
            with open(archive_path, "rb") as compressed:
                dctx = zstd.ZstdDecompressor()
                with tempfile.NamedTemporaryFile(
                    delete=False, suffix=".tar"
                ) as decompressed:
                    dctx.copy_stream(compressed, decompressed)
                    tar_path = decompressed.name

            # Extract tar
            with tarfile.open(tar_path, "r") as tar:
                tar.extractall(tmpdir)

            # Clean up temporary tar file
            os.unlink(tar_path)

            # Verify critical files exist
            tmpdir_path = Path(tmpdir)
            critical_files = [
                "bin/lldb",
                "bin/lldb-server",
                "lib/liblldb.so.21",
                "python/Lib/site-packages/lldb/__init__.py",
            ]

            for rel_path in critical_files:
                file_path = tmpdir_path / rel_path
                if not file_path.exists():
                    print_error(f"Missing critical file in archive: {rel_path}")
                    return False

            print_success("Archive extraction test passed")
            return True

        except Exception as e:
            print_error(f"Failed to extract archive: {e}")
            return False


def update_manifest(
    manifest_path: Path, archive_path: Path, checksum_path: Path, dry_run: bool
) -> bool:
    """Update manifest file with archive metadata"""
    print_info(
        f"Updating manifest: {manifest_path.relative_to(manifest_path.parents[3])}..."
    )

    # Read current manifest
    with open(manifest_path) as f:
        manifest = json.load(f)

    # Read checksum
    with open(checksum_path) as f:
        checksum_line = f.read().strip()
        checksum = checksum_line.split()[0]

    # Get file size
    file_size = archive_path.stat().st_size
    file_size_mb = file_size / (1024 * 1024)

    # Update manifest fields
    manifest["sha256"] = checksum
    manifest["compressed_size_bytes"] = file_size
    manifest["compressed_size_mb"] = round(file_size_mb, 2)

    # Ensure python_bundled is set
    if "python_bundled" not in manifest:
        manifest["python_bundled"] = True

    if "python_version" not in manifest:
        manifest["python_version"] = "3.10"

    print_info(f"  Archive size: {file_size_mb:.2f} MB")
    print_info(f"  SHA256: {checksum[:16]}...")
    print_info(f"  Python bundled: {manifest['python_bundled']}")

    if dry_run:
        print_warning("Dry-run mode: Manifest not updated")
        return True

    # Write updated manifest
    with open(manifest_path, "w") as f:
        json.dump(manifest, f, indent=2)
        f.write("\n")  # Add trailing newline

    print_success("Manifest updated successfully")
    return True


def move_archive(source_path: Path, dest_path: Path, dry_run: bool) -> bool:
    """Move archive to distribution directory"""
    print_info(f"Moving archive to: {dest_path.relative_to(dest_path.parents[3])}...")

    dest_path.parent.mkdir(parents=True, exist_ok=True)

    if dry_run:
        print_warning("Dry-run mode: Archive not moved")
        return True

    shutil.copy2(source_path, dest_path)
    print_success("Archive moved successfully")
    return True


def integrate_architecture(
    arch: str, artifacts_dir: Path, assets_dir: Path, dry_run: bool
) -> bool:
    """Integrate archives and manifests for one architecture"""
    print_section(f"Integrating Linux {arch} LLDB Archive")

    # Define paths
    artifact_dir = artifacts_dir / f"lldb-linux-{arch}"
    archive_name = f"lldb-21.1.5-linux-{arch}.tar.zst"
    checksum_name = f"{archive_name}.sha256"

    archive_path = artifact_dir / archive_name
    checksum_path = artifact_dir / checksum_name

    dest_dir = assets_dir / "lldb" / "linux" / arch
    dest_archive_path = dest_dir / archive_name
    manifest_path = dest_dir / "manifest.json"

    # Verify artifact files exist
    if not archive_path.exists():
        print_error(f"Archive not found: {archive_path}")
        return False

    if not checksum_path.exists():
        print_error(f"Checksum file not found: {checksum_path}")
        return False

    # Verify checksum
    if not verify_checksum(archive_path, checksum_path):
        return False

    # Test extraction
    if not test_archive_extraction(archive_path):
        return False

    # Move archive to destination
    if not move_archive(archive_path, dest_archive_path, dry_run):
        return False

    # Update manifest
    if not update_manifest(manifest_path, archive_path, checksum_path, dry_run):
        return False

    print_success(f"Linux {arch} integration complete!")
    return True


def main():
    parser = argparse.ArgumentParser(
        description="Integrate Linux LLDB archives into clang-tool-chain distribution",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Download and integrate from latest workflow run
  %(prog)s

  # Download from specific run ID
  %(prog)s --run-id 12345678

  # Dry-run mode (no changes)
  %(prog)s --dry-run

  # Skip download (use existing artifacts)
  %(prog)s --skip-download --artifacts-dir ./my-artifacts

  # Integrate only x86_64
  %(prog)s --arch x86_64
        """,
    )

    parser.add_argument(
        "--run-id",
        type=str,
        help="GitHub Actions run ID (auto-detects latest if not specified)",
    )

    parser.add_argument(
        "--arch",
        type=str,
        choices=["x86_64", "arm64"],
        help="Architecture to integrate (default: both)",
    )

    parser.add_argument(
        "--skip-download",
        action="store_true",
        help="Skip artifact download (use existing files)",
    )

    parser.add_argument(
        "--artifacts-dir",
        type=Path,
        default=Path("artifacts"),
        help="Directory containing downloaded artifacts (default: ./artifacts)",
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Dry-run mode: verify but don't modify files",
    )

    args = parser.parse_args()

    # Determine architectures to process
    architectures = [args.arch] if args.arch else ["x86_64", "arm64"]

    # Determine project root (downloads-bins directory)
    script_dir = Path(__file__).parent.resolve()
    downloads_bins_root = script_dir.parent
    assets_dir = downloads_bins_root / "assets"

    print_section("Linux LLDB Archive Integration")
    print_info(f"Downloads-bins root: {downloads_bins_root}")
    print_info(f"Assets directory: {assets_dir}")
    print_info(f"Architectures: {', '.join(architectures)}")

    if args.dry_run:
        print_warning("DRY-RUN MODE: No changes will be made")

    # Check prerequisites
    if not args.skip_download:
        if not check_gh_cli():
            return 1

        # Get run ID
        run_id = args.run_id
        if not run_id:
            run_id = get_latest_workflow_run()
            if not run_id:
                print_error(
                    "Failed to find workflow run. Specify --run-id manually or use --skip-download"
                )
                return 1

        # Download artifacts
        if not download_artifacts(run_id, args.artifacts_dir, architectures):
            return 1
    else:
        print_info("Skipping artifact download (using existing files)")

    # Verify artifacts directory exists
    if not args.artifacts_dir.exists():
        print_error(f"Artifacts directory not found: {args.artifacts_dir}")
        return 1

    # Integrate each architecture
    success = True
    for arch in architectures:
        if not integrate_architecture(
            arch, args.artifacts_dir, assets_dir, args.dry_run
        ):
            success = False
            print_error(f"Failed to integrate {arch}")

    # Final summary
    print_section("Integration Summary")

    if success:
        print_success("All architectures integrated successfully!")

        if not args.dry_run:
            print_info("\nNext steps:")
            print_info(
                "  1. Review manifest changes: git diff downloads-bins/assets/lldb/linux/*/manifest.json"
            )
            print_info("  2. Test installation: clang-tool-chain install lldb")
            print_info("  3. Run tests: pytest tests/test_lldb.py -v")
            print_info("  4. Commit changes: git add downloads-bins/assets/lldb/linux/")
            print_info(
                "  5. Update main repo submodule: git add downloads-bins && git commit"
            )
        else:
            print_warning("\nDry-run complete. Run without --dry-run to apply changes.")

        return 0
    else:
        print_error("Integration failed for one or more architectures")
        return 1


if __name__ == "__main__":
    sys.exit(main())
